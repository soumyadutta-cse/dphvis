# Workshop on Visualization for the Digital and Public Humanities (DPH-Vis)

### In conjunction with [IEEE Pacific Visualization Conference 2025](https://pacificvis2025.github.io/pages/index.html)

<br>
<img src="images/photo-collage.png" alt="collage" style="width: 2000px; height: 400px;">
<br>
<br>

## Workshop Date

Tuesday, April 22, 2025

## Workshop Theme

Digital Humanities is a research field that aims to bring new insights to the humanities through scientific methodologies centered on computer science and technology. In the current era of big data, the digital data handled by Digital Humanities has become more complex, massive, and multi-source.

In this context, a new trend in Digital Humanities has emerged, aiming to involve a broader range of people from various fields in discussions within the humanities through interdisciplinary research utilizing digital technologies. This trend is known as "Digital and Public Humanities (DPH)." In this interdisciplinary fusion, visualization should play an essential role. Therefore, we are launching a new workshop titled "Workshop on Visualization for the Digital and Public Humanities (DPH-Vis)" as part of PacificVis 2025. This workshop is not just a gathering but a platform that fosters new interdisciplinary collaboration. We welcome researchers from various fields, both in scientific and humanities areas.

Visualization for DPH involves a variety of visualizations: high-quality visualization,
feature-highlighting visualization, AI-assisted visualization, immersive visualization, visualization of digital twins, multi-source/multi-dimensional visualization, time-series visualization, story-telling visualization, and many others. We welcome research contributions to any visualization and visual analytics targeting humanities data.

## Participation/Call for Papers

We invite original, unpublished short papers of up to 6 pages including references. Please note that 6 pages is the length limit, not the expected length. Manuscripts should be prepared according to the guide for authors given at [https://tc.computer.org/vgtc/publications/conference/](https://tc.computer.org/vgtc/publications/conference/).

## Submission and Review Process

The worksho will use the [Precision Conference System (PCS)](https://new.precisionconference.com/user/login) to handle the submission and reviewing process. When submitting, at the top of the PCS Submissions tab, please select 'VGTC' for the society, 'PacificVis 2025' for the conference/journal, and 'PacificVis 2025 Workshop on Visualization for Digial and Public Humanities' for the track. All submissions will be peer-reviewed by field experts and evaluated based on their relevance to the workshop theme, technical rigor, creativity, originality, and the impact of the methods or results. The workshop will follow a double blind review system.

## Publication

We are in touch with IEEE to get approval for the accepted papers to be published in the IEEE Xplore Digital Library.

## Timeline/Important Dates

Submission deadline: January 6, 2025<br>
Notification: February 12, 2025<br>
Camera ready deadline: February 22, 2025<br>

<br>

## Keynote Speaker

### Prof. Chongke Bi, College of Intelligence and Computing, Tianjin University, China

<div style="display: flex; align-items: center; justify-content: flex-start;">
  <div style="margin-right: 20px; text-align: center;">
    <img src="images/keynote_speaker.jpg" alt="Chongke Bi" style="border-radius: 50%; width: 150px; height: 170px;">
  </div>
</div>

### Title: Emotion-Driven Talking Face Generation for Digital Humanities

### Abstract:

Emotion-driven talking face generation is a crucial and rapidly developing technology in the field of digital humanities. For example, it can be used to reconstruct the likeness of historical figures, bringing them “to life” to help people better understand history and culture. It can even enable historical figures to engage in multilingual communication, promoting cultural exchange on an international level. Additionally, it can be applied in virtual tour guides, allowing users to customize the likeness of their favorite celebrities as guides. Emotion-driven talking face generation involves transferring facial motion attributes from audio or video onto any portrait image to generate realistic talking face videos. In the domain of representation learning, one of the key challenges for this technology is effectively disentanglement facial expressions and head poses to achieve more natural and precise control in video editing and human-computer interaction. This talk will introduce our recent work for disentanglement speaking motion representations based on prior knowledge, such as the attention disentanglement model, 3DMM model, and Facial Action Coding System (FACS). Additionally, the application of generative models like GAN and NeRF in the task of talking face synthesis will also be discussed. Finally, several digital humanities applications will also be shown.

### Speaker Bio:

Chongke Bi received his BSc (Eng.) and MSc (Eng.) degrees from Shandong University in 2004 and 2007, respectively, and his PhD (Sci.) degree from The University of Tokyo, Japan, in 2012. From 2012 to 2016, he was a Researcher at RIKEN, Japan, where he focused on the research in the field of visual analysis of large-scale simulation on supercomputer. He is currently a professor at the college of intelligence and computing, Tianjin University. His research interests include visualization, machine learning, and high performance computing. He was the Organizing Chair of the 13th and 14th IEEE Pacific Visualization Symposium (IEEE PacificVis 2020 and 2021); the Poster Chair of IEEE PacificVis 2018. He was also served as the Program Co-chair of the 17th International Symposium on Visual Information Communication and Interaction (VINCI 2024). He has been the Chair of the International Forum in ChinaVis since 2018; the Chair of CSIG-VIS International Lecture Series since 2021 (https://chinavis.org/lectures/english/index_en.html).

<br>

## Committee and Chairs

#### Workshop Chairs

<br>
<div style="display: flex; align-items: center; justify-content: flex-start;">
  <div style="margin-right: 20px; text-align: center;">
    <img src="images/sdutta.png" alt="Soumya Dutta" style="border-radius: 50%; width: 150px; height: 150px;">
    <p style="margin: 10px 0 0;">Soumya Dutta</p>
    <p style="margin: 0;">IIT Kanpur, India</p>
  </div>
  <div style="text-align: center;">
    <img src="images/tanaka.png" alt="Satoshi Tanaka" style="border-radius: 50%; width: 150px; height: 150px;">
    <p style="margin: 10px 0 0;">Satoshi Tanaka</p>
    <p style="margin: 0;">Ritsumeikan University, Japan</p>
  </div>
</div>

<br>

#### Program Committee

1. Hiroaki Natsukawa, Osaka Seikei University, Japan
2. Satoshi Takatori, Ritsumeikan University, Japan
3. Liang Li, Ritsumeikan University, Japan
4. Jiao Pan, University of Science and Technology Beijing, China
5. Weite Li, Chongqing Technology and Business University, China

### Contact Us

- Soumya Dutta, Workshop Chair, soumyad at cse dot iitk dot ac dot in
- Satoshi Tanaka, Workshop Chair, stanaka at is dot ritsumei dot ac dot jp
